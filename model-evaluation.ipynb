{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c6d40d-26f7-4b83-a3a3-fc9c84e848cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing useful functions\n",
    "import sys\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1f6ad0-9d06-438f-9289-c41d79486830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and formatting data\n",
    "\n",
    "case_csv = 'nsclc_rpk.csv'\n",
    "control_csv = 'healthy_rpk.csv'\n",
    "\n",
    "case_df = pd.read_csv(open(case_csv, 'r'), header = 0, index_col = 0)\n",
    "control_df = pd.read_csv(open(control_csv, 'r'), header = 0, index_col = 0)\n",
    "\n",
    "# transpose\n",
    "case_df = case_df.T\n",
    "control_df = control_df.T\n",
    "\n",
    "# log-transform\n",
    "case_df = case_df.transform(lambda x: np.log2(x+1))\n",
    "control_df = control_df.transform(lambda x: np.log2(x+1))\n",
    "\n",
    "# load into lists\n",
    "pos_list = case_df.values\n",
    "neg_list = control_df.values\n",
    "\n",
    "print(len(pos_list))\n",
    "print(len(neg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1142ed-b4a3-431b-a55a-f7b87f7a6f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch architecture\n",
    "class torch_NN(nn.Module):\n",
    "    def __init__(self,input_features):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_features, 100)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(100, 50)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(50, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "def train_NN(model, X_train, y_train):\n",
    "\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    number_epochs = 500\n",
    "    batch_size = len(X_train)\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "    for epoch in range(number_epochs):\n",
    "        model.train()\n",
    "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_function(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ded408-3779-4ded-8b37-5ab59f9eab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation by X-fold cross-validation\n",
    "\n",
    "number_slices = 10\n",
    "\n",
    "pos_number = len(pos_list)\n",
    "neg_number = len(neg_list)\n",
    "pos_slice_size = int(len(pos_list)/number_slices)\n",
    "neg_slice_size = int(len(neg_list)/number_slices)\n",
    "pos_extra_slices = len(pos_list) % number_slices\n",
    "neg_extra_slices = len(neg_list) % number_slices\n",
    "\n",
    "np.random.seed(5)\n",
    "pos_test_list = np.random.choice(len(pos_list), len(pos_list), replace = False)\n",
    "np.random.seed(5)\n",
    "neg_test_list = np.random.choice(len(neg_list), len(neg_list), replace = False)\n",
    "test_predictions = []\n",
    "test_probs = []\n",
    "test_labels = []\n",
    "\n",
    "pos_index = 0\n",
    "neg_index = 0\n",
    "\n",
    "# k-fold cross-validation\n",
    "\n",
    "for k_slice in range(0,number_slices):\n",
    "\n",
    "    training_input = []\n",
    "    training_output = []\n",
    "    test_input = []\n",
    "    test_output= []\n",
    "\n",
    "    if k_slice < pos_extra_slices:\n",
    "        new_pos_index = pos_index + pos_slice_size + 1\n",
    "    else:\n",
    "        new_pos_index = pos_index + pos_slice_size\n",
    "    pos_test_indices = list(pos_test_list[pos_index:new_pos_index])\n",
    "    pos_index = new_pos_index\n",
    "\n",
    "    for index in range(len(pos_list)):\n",
    "        if index not in pos_test_indices:\n",
    "            training_input.append(pos_list[index])\n",
    "            training_output.append(1)\n",
    "        else:\n",
    "            test_input.append(pos_list[index])\n",
    "            test_output.append(1)\n",
    "\n",
    "    if k_slice < neg_extra_slices:\n",
    "        new_neg_index = neg_index + neg_slice_size + 1\n",
    "    else:\n",
    "        new_neg_index = neg_index + neg_slice_size\n",
    "    neg_test_indices = list(neg_test_list[neg_index:new_neg_index])\n",
    "    neg_index = new_neg_index\n",
    "\n",
    "    for index in range(len(neg_list)):\n",
    "        if index not in neg_test_indices:\n",
    "            training_input.append(neg_list[index])\n",
    "            training_output.append(0)\n",
    "        else:\n",
    "            test_input.append(neg_list[index])\n",
    "            test_output.append(0)\n",
    "\n",
    "'''\n",
    "# neural network\n",
    "    model_name = \"Neural Network\"\n",
    "    nn_model = torch_NN(input_features = number_features)\n",
    "    clf = train_NN(nn_model, torch.tensor(training_input, dtype=torch.float32), torch.tensor(training_output, dtype=torch.float32).unsqueeze(-1))\n",
    "    predictions = clf(test_input)\n",
    "    for item in predictions:\n",
    "        test_probs.append([float(i) for i in predictions[0]])\n",
    "        test_labels.append([float(i) for i in predictions[1]])\n",
    "\n",
    "# sklearn models\n",
    "    model_name = \"Logistic Regression\"\n",
    "    clf = LogisticRegression(penalty = 'l2', random_state=None, solver = 'liblinear', max_iter = 500).fit(training_input, training_output)\n",
    "\n",
    "    model_name = \"Support Vector Machine\"\n",
    "    clf = SVC(kernel = 'rbf',probability = True, random_state = None, max_iter = 500).fit(training_input,training_output)\n",
    "\n",
    "    model_name = \"Random Forest\"\n",
    "    clf = RandomForestClassifier(n_estimators = 1000, random_state = None, max_iter = 500).fit(training_input, training_output)\n",
    "'''\n",
    "\n",
    "    predictions = clf.predict(test_input)\n",
    "    for item in predictions:\n",
    "        test_predictions.append(item)\n",
    "    prob_array = clf.predict_proba(test_input)\n",
    "    for item in prob_array:\n",
    "        test_probs.append(item[1])\n",
    "    for label in test_output:\n",
    "        test_labels.append(label)\n",
    "\n",
    "    print(\"Fold done: \" + str(k_slice + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8781551-c52b-4e9b-a0e2-e8aadc91366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting results\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_labels, test_probs, pos_label = 1.0)\n",
    "ROC_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='red', lw=lw, label='AUC = %0.2f' % ROC_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('%s: Case (n=%i) vs. Control (n=%i)' % (model_name, pos_number, neg_number) )\n",
    "plt.legend(loc=\"lower right\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
